---
---

# Uncovering neural algorithms for learning

Performing an ace tennis serve or checkmating an opponent in chess can seem like daunting tasks for a novice. Yet we take it for granted that, given enough practice and time, we can all become expert practitioners of such skills. The brainâ€™s ability to solve complex learning challenges is an incredible feat whose speed and efficiency is unmatched by machine intelligence. However, little is known about this ability and the neural circuits that underlie it. 

This is because most laboratory studies of learning typically focus on simple tasks that can be solved within a few sessions. In contrast acquiring a new skill is a noisy, trial-and-error driven process that typically spans weeks and months. Thus, to understand the neural basis of skill learning, we need new approaches to monitor changes in behaviour and neural activity over these long timescales. 

We employ an interdisciplinary strategy to investigate the neural basis of skill learning in rodents. (1) Using a fully-automated behavioural training system we acquire large datasets as animals learn to solve complex motor and foraging tasks. (2) We infer trial-by-trial learning strategies by performing detailed analysis of these massive datasets in concert with computational modelling utilizing reinforcement learning theory. (3) Using targeted perturbations of neural circuits in combination with a new experimental platform to automatically record the spiking activity of large ensembles of neurons continuously (24/7) over weeks and months in behaving animals, we investigate how the learning algorithms we have identified through behavioural analysis are implemented in the brain.


{%
  include figure.html
  image="images/team/lab-pic-casual.jpg"
  link="team"
  title="Our Team"
  text=text
%}
